/*
 * -----------------------------------------------------------
 *  Config file for execution on HPC
 * -----------------------------------------------------------
 * Specification for a larger resource amount (e.g., CPU number) for each process
 *
 */

// HPC-specific params
executor {
    name            = 'slurm'
    queueSize       = 200
    submitRateLimit = '5 sec'
    pollInterval    = '1sec'
    retry.delay     = '1sec'
}

env {
    OPENBLAS_NUM_THREADS=1
    OMP_NUM_THREADS=1
}

// Process configuration
process {

    // Cluster-specific options (e.g., partition name, billing account, etc.)
    clusterOptions = '-p amd'

    // Error strategy
    errorStrategy = { task.exitStatus in [1,104,125,130,134,135,137,139,140,143,255] ? 'retry' : 'finish' }
    maxRetries    = 3
    maxErrors     = '-1'

    // Default resources
    cpus   = { check_max( 1    * task.attempt, 'cpus'   ) }
    memory = { check_max( 2.GB * task.attempt, 'memory' ) }
    time   = { check_max( 3.h  * task.attempt, 'time'   ) }

    ////////// Step-1 processes

    // Converting BAM to FASTQ
    withName: 'S1:bam2fastq' {
        cpus   = 12
        memory = 2.GB
        time   = { check_max( 4.h  * task.attempt, 'time' ) }
    }

    // Primer disambiguation
    withName: 'S1:disambiguate' {
        cpus   = 1
        memory = 1.GB
        time   = 20.m
    }

    // Validate tags for demultiplexing
    withName: 'S1:tag_validation' {
        cpus   = 1
        memory = 1.GB
        time   = 20.m
    }

    // QC - PacBio single-end reads
    // vsearch currently does not suppot multithreading for `--fastq_filter`
    // see https://github.com/torognes/vsearch/issues/466
    withName: 'S1:qc_se' {
        cpus   = 2              // for pipes
        memory = 1.GB
        time   = { check_max( 2.h  * task.attempt, 'time' ) }
    }

    // QC - Illumina paired-end reads
    withName: 'S1:qc_pe' {
        // max threads for fastp = 16
        cpus   = 12
        memory = 20.GB
        time   = 4.h
    }

    // Demultiplexing of PacBio reads (with LIMA)
    withName: 'S1:demux' {
        cpus   = 12
        memory = { check_max( 3.GB * task.attempt, 'memory' ) }
        time   = { check_max( 1.h  * task.attempt, 'time'   ) }
    }

    // Demultiplexing merged Illumina reads
    withName: 'S1:demux_illumina' {
        cpus   = 16
        memory = 20.GB
        time   = 4.h
    }

    // Demultiplexing non-merged Illumina reads
    withName: 'S1:demux_illumina_notmerged' {
        cpus   = 10
        memory = 20.GB
        time   = 4.h
    }

    // Merging of Illumina PE reads
    withName: 'S1:merge_pe' {
        cpus   = 8
        memory = 20.GB
        time   = 4.h
    }
    
   // Demultiplexing of Illumina reads (with cutadapt)
    withName: 'S1:demux_illumina' {
        cpus   = 16
        memory = 20.GB
        time   = 4.h
    }

    // Check primers
    withName: 'S1:primer_check' {
        cpus   = 1
        memory = 1.GB
        time   = { check_max( 30.m * task.attempt, 'time'   ) }
    }

    // ITSx
    withName: 'S1:itsx' {
        cpus   = 20
        memory = { check_max( 10.GB  * task.attempt, 'memory' ) }
        time   = { check_max( 20.h  * task.attempt, 'time'   ) }
    }

    // Collect all ITS parts extracted by ITSx
    withName: 'S1:itsx_collect' {
        cpus   = 1
        memory = 1.GB
        time   = { check_max( 30.m  * task.attempt, 'time'   ) }
    }

    // Sequence quality tables
    withName: 'S1:seq_qual' {
        cpus   = 6
        memory = { check_max( 50.GB * task.attempt, 'memory' ) }
        time   = { check_max( 1.h   * task.attempt, 'time'   ) }
    }

    // Homopolymer compression
    withName: 'S1:homopolymer' {
        cpus = 2
        memory = 2.GB
        time   = { check_max( 3.h  * task.attempt, 'time'   ) }
    }

    // Reference-based chimera removal
    withName: 'S1:chimera_ref' {
        cpus = 4
        memory = { check_max( 3.GB * task.attempt, 'memory' ) }
        time   = { check_max( 1.h  * task.attempt, 'time'   ) }
    }

    // Chimera rescue
    withName: 'S1:chimera_rescue' {
        cpus   = 1
        memory = { check_max( 1.GB * task.attempt, 'memory' ) }
        time   = { check_max( 1.h  * task.attempt, 'time'   ) }
    }

    // De novo chimera search
    withName: 'S1:chimera_denovo' {
        cpus   = 1
        memory = { check_max( 1.GB * task.attempt, 'memory' ) }
        time   = { check_max( 1.h  * task.attempt, 'time'   ) }
    }

    // Aggregate de novo chimeras
    withName: 'S1:chimera_denovo_agg' {
        cpus   = 1
        memory = 1.GB
        time   = { check_max( 1.h  * task.attempt, 'time'   ) }
    }

    // Global dereplication
    withName: 'S1:glob_derep' {
        cpus   = 1
        memory = { check_max( 2.GB * task.attempt, 'memory' ) }
        time   = { check_max( 1.h  * task.attempt, 'time'   ) }
    }

    // Pool sequences (for ASV table)
    withName: 'S1:pool_seqs' {
        cpus   = 2
        memory = { check_max( 1.GB * task.attempt, 'memory' ) }
        time   = { check_max( 30.m * task.attempt, 'time'   ) }
    }

    // OTU clustering
    withName: 'S1:tj_preclust' {
        cpus   = 12
        memory = { check_max( 12.GB * task.attempt, 'memory' ) }
        time   = { check_max( 4.h   * task.attempt, 'time'   ) }
    }

    // Tag-jump removal
    withName: 'S1:tj' {
        cpus   = 1
        memory = { check_max( 2.GB  * task.attempt, 'memory' ) }
        time   = { check_max( 30.m  * task.attempt, 'time'   ) }
    }

    // Create sequence table
    withName: 'S1:prep_seqtab' {
        cpus   = 8
        memory = { check_max( 50.GB * task.attempt, 'memory' ) }
        time   = { check_max( 30.m  * task.attempt, 'time'   ) }
    }

    // Read count summary
    withName: 'S1:read_counts' {
        cpus = 4
        memory = { check_max( 1.GB * task.attempt, 'memory' ) }
        time   = { check_max( 30.m * task.attempt, 'time'   ) }
    }


    ////////// Step-2 processes

    // Aggregate sequences, remove de novo chimeras
    withName: 'S2:aggregate_sequences' {
        cpus = 12
        memory = { check_max( 40.GB * task.attempt, 'memory' ) }
        time   = { check_max( 1.h   * task.attempt, 'time'   ) }
    }

    // Dereplication (only comression is multithreaded)
    withName: 'S2:dereplication' {
        cpus   = 20
        memory = { check_max( 4.GB * task.attempt, 'memory' ) }
        time   = { check_max( 5.h * task.attempt, 'time'   ) }
    }
    
    // 100% clustering with sequence length variation allowed (UNITE-style)
    withName: 'S2:dereplication_unite' {
        cpus   = 20
        memory = { check_max( 50.GB * task.attempt, 'memory' ) }
        time   = { check_max( 24.h  * task.attempt, 'time'   ) }
    }

    // Pre-clustering
    withName: 'S2:linclust' {
        cpus = 20
        memory = { check_max( 50.GB * task.attempt, 'memory' ) }
        time   = { check_max( 1.h   * task.attempt, 'time'   ) }
    }

    // Bucketize sequences into clusters
    withName: 'S2:bucketize' {
        cpus = 6
        memory = { check_max( 50.GB * task.attempt, 'memory' ) }
        time   = { check_max( 2.h   * task.attempt, 'time'   ) }
    }

    // UNOISE
    withName: 'S2:CLUSTERING:unoise' {
        cpus   = 30
        memory = { check_max( 40.GB * task.attempt, 'memory' ) }
        time   = { check_max( 30.h  * task.attempt, 'time'   ) }
    }

    // DADA2
    withName: 'S2:CLUSTERING:dada2' {
        cpus   = 30
        memory = { check_max( 60.GB * task.attempt, 'memory' ) }
        time   = { check_max( 30.h  * task.attempt, 'time'   ) }
    }

    // VSEARCH clustering
    withName: 'S2:CLUSTERING:cluster_vsearch' {
        cpus   = 30
        memory = { check_max( 80.GB * task.attempt, 'memory' ) }
        time   = { check_max( 30.h  * task.attempt, 'time'   ) }
    }

    // SWARM clustering
    withName: 'S2:CLUSTERING:cluster_swarm' {
        cpus   = 30
        memory = { check_max( 80.GB * task.attempt, 'memory' ) }
        time   = { check_max( 24.h  * task.attempt, 'time'   ) }
    }

    // Summarize sequence abundance by OTU
    withName: 'S2:summarize' {
        cpus   = 2
        memory = { check_max( 20.GB * task.attempt, 'memory' ) }
        time   = { check_max( 5.h   * task.attempt, 'time'   ) }
    }

    // Post-clustering curation with LULU
    withName: 'S2:lulu' {
        cpus   = 30
        memory = { check_max( 60.GB * task.attempt, 'memory' ) }
        time   = { check_max( 24.h  * task.attempt, 'time'   ) }
    }

}


// Function to ensure that resource requirements don't go beyond a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

